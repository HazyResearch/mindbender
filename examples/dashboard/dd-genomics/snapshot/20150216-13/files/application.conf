deepdive {

  db.default {
    driver   : "org.postgresql.Driver"
    url      : "jdbc:postgresql://"${PGHOST}":"${PGPORT}"/"${DBNAME}
    user     : ${PGUSER}
    password : ${PGPASSWORD}
    dbname   : ${DBNAME}
    host     : ${PGHOST}
    port     : ${PGPORT}
	  gphost   : ${GPHOST}
	  gpport   : ${GPPORT}
	  gppath   : ${GPPATH}
	# start gpfdist server on the machine running the application with
	# `rungpcommand 'gpfdist -d /lfs/raiders4/0/rionda/greenplum_gpfdist -p 8888'`
  }

  # Parallel grounding for GreenPlum
  inference.parallel_grounding: true

  # holdout fraction for calibration
  # calibration.holdout_fraction: 0.1
  calibration: {
    holdout_query: """
      INSERT INTO dd_graph_variables_holdout(variable_id) SELECT g.id FROM gene_hpoterm_relations g, random_doc_id r WHERE g.doc_id = r.doc_id;
      INSERT INTO dd_graph_variables_holdout(variable_id) SELECT g.id FROM gene_mentions g, random_doc_id r WHERE g.doc_id = r.doc_id;
      INSERT INTO dd_graph_variables_holdout(variable_id) SELECT g.id FROM hpoterm_mentions g, random_doc_id r WHERE g.doc_id = r.doc_id;
    """
  }
  
  # Execute one extractor at a time (but we use parallelism for extractors)
  extraction.parallelism: 1


### EXTRACTORS ###
  extraction.extractors {
      
### SENTENCES -> SENTENCES_INPUT ###
    
    # Generate the sentences_input table from the sentences table  
    new_sentence: {
      style: sql_extractor
      sql: """
        DROP TABLE IF EXISTS sentences_input CASCADE;
        CREATE TABLE sentences_input
        AS select 
       -- document id
       doc_id,
       -- sentence id
       sent_id,
       -- word indexes
       array_to_string(wordidxs, '|^|') AS wordidxs,
       -- words text[],
       array_to_string(words, '|^|') AS words,
       -- parts of speech
       array_to_string(poses, '|^|') AS poses,
       -- named entity recognition tags
       array_to_string(ners, '|^|') AS ners,
       -- lemmified version of words
       array_to_string(lemmas, '|^|') AS lemmas,
       -- dependency path labels
       array_to_string(dep_paths, '|^|') AS dep_paths,
       -- dependency path parents
       array_to_string(dep_parents, '|^|') AS dep_parents,
       -- bounding boxes
       array_to_string(bounding_boxes, '|^|') AS bounding_boxes
       FROM sentences;
      """
    }

### GENES ###

    # Find acronyms in documents
    ext_gene_find_acronyms: {
      before: ${APP_HOME}/code/truncate_table.sh ${DBNAME} acronyms
      style: tsv_extractor
      input: """SELECT
            doc_id,
            array_to_string(array_accum(sent_id), '|^|'),
            array_to_string(array_accum(wordidxs), '!~!'),
            array_to_string(array_accum(words), '!~!'),
            array_to_string(array_accum(poses), '!~!'),
            array_to_string(array_accum(ners), '!~!'),
            array_to_string(array_accum(lemmas), '!~!'),
            array_to_string(array_accum(dep_paths), '!~!'),
            array_to_string(array_accum(dep_parents), '!~!'),
            array_to_string(array_accum(bounding_boxes), '!~!')
          FROM
            sentences_input
          GROUP BY doc_id
          """
      output_relation: acronyms
      udf: ${APP_HOME}/code/ext_gene_find_acronyms.py
      parallelism: ${PARALLELISM}
      dependencies: [new_sentence]
    }

    # Extract gene mention candidates
    ext_gene_candidates: {
      before: ${APP_HOME}/code/truncate_table.sh ${DBNAME} gene_mentions
      style: tsv_extractor
      input: """SELECT doc_id,
              sent_id,
              wordidxs,
              words,
              poses,
              ners,
              lemmas
          FROM sentences_input"""
      output_relation: gene_mentions
      udf: ${APP_HOME}/code/ext_gene_candidates.py
      parallelism: ${PARALLELISM}
      dependencies: [new_sentence]
    }

    # Supervise the gene mention candidates using the acronyms
    ext_gene_superv_acronyms: {
      style: sql_extractor
      sql: """UPDATE gene_mentions
          SET 
            is_correct = a.is_correct,
            type = 'GENE_SUP_ACR',
            mention_id = regexp_replace(gene_mentions.mention_id, 'MENTION_GENE', 'MENTION_GENE_SUP_ACR')
          FROM 
            acronyms a
          WHERE 
            a.is_correct IS NOT NULL
          AND
            gene_mentions.type = 'GENE'
          AND
            gene_mentions.doc_id = a.doc_id
          AND
            gene_mentions.words[1] = a.acronym
        """
      dependencies: [ext_gene_find_acronyms, ext_gene_candidates]
    }

    # For each supervised gene mention candidate, add an unsupervised copy
    ext_gene_unsuperv_dupl: {
      style: sql_extractor
      sql: """INSERT INTO gene_mentions
          SELECT
            id, 
            doc_id, 
            sent_id, 
            wordidxs, 
            mention_id || '_UNSUP',
            type || '_UNSUP',
            entity,
            words,
            NULL,
            features
          FROM
            gene_mentions
          WHERE
            is_correct IS NOT NULL
          AND type <> 'GENE_SUP_contr_2'
          AND type <> 'GENE_SUP_contr_1'
          """
      dependencies: [ext_gene_superv_acronyms, ext_genepheno_relations]
    }

    # Add features to all gene candidates (that are not generifs)
    ext_gene_features: {
      before: ${APP_HOME}/code/truncate_table.sh ${DBNAME} gene_features
      style: tsv_extractor
      input: """SELECT
              t0.doc_id,
              t0.sent_id,
              t0.wordidxs,
              t0.words,
              t0.poses,
              t0.ners,
              t0.lemmas,
              t0.dep_paths,
              t0.dep_parents,
              t1.mention_id,
              array_to_string(t1.wordidxs, '|^|')
           FROM
              sentences_input t0,
              gene_mentions t1
          WHERE
              t0.doc_id = t1.doc_id and t0.sent_id = t1.sent_id
          """
      output_relation: gene_features
      udf: ${APP_HOME}/code/ext_gene_features.py
      parallelism: ${PARALLELISM}
      dependencies: [ext_gene_unsuperv_dupl]
    }

    # Extract gene mention candidates from the generifs
    ext_generifs_candidates: {
      before: ${APP_HOME}/code/truncate_table.sh ${DBNAME} generifs_mentions
      style: tsv_extractor
      input: """SELECT
              doc_id,
              sent_id,
              array_to_string(wordidxs, '|^|'),
              array_to_string(words, '|^|'),
              array_to_string(poses, '|^|'),
              array_to_string(ners, '|^|'),
              array_to_string(lemmas, '|^|'),
              array_to_string(dep_paths, '|^|'),
              array_to_string(dep_parents, '|^|'),
              array_to_string(bounding_boxes, '|^|'),
              gene
            FROM
              generifs
            """
      output_relation: generifs_mentions
      udf: ${APP_HOME}/code/ext_generifs_candidates.py
      dependencies = [ext_gene_features]
      parallelism: ${PARALLELISM}
    }

    # Add the generifs extractions to the gene mentions table
    add_generifs_candidates: {
      style: sql_extractor
      sql: """INSERT INTO gene_mentions SELECT * FROM generifs_mentions"""
      dependencies = [ext_generifs_candidates, ext_gene_candidates, ext_gene_features]
    }

    # Add features to all generifs candidates
    ext_generifs_features: {
      before: ${APP_HOME}/code/truncate_table.sh ${DBNAME} generifs_features
      style: tsv_extractor
      input: """SELECT
              t0.doc_id,
              t0.sent_id,
              array_to_string(t0.wordidxs, '|^|'),
              array_to_string(t0.words, '|^|'),
              array_to_string(t0.poses, '|^|'),
              array_to_string(t0.ners, '|^|'),
              array_to_string(t0.lemmas, '|^|'),
              array_to_string(t0.dep_paths, '|^|'),
              array_to_string(t0.dep_parents, '|^|'),
              t1.mention_id,
              array_to_string(t1.wordidxs, '|^|')
           FROM
              generifs t0,
              generifs_mentions t1
          WHERE
              t0.doc_id = t1.doc_id and t0.sent_id = t1.sent_id
          """
      output_relation: generifs_features
      udf: ${APP_HOME}/code/ext_gene_features.py
      dependencies: [ext_generifs_candidates]
      parallelism: ${PARALLELISM}
    }

    # Add generifs features to the gene_features table
    add_generifs_features: {
      style: sql_extractor
      sql: """INSERT INTO gene_features SELECT * FROM generifs_features"""
      dependencies = [ext_generifs_features, ext_gene_features]
    }

### PHENOTYPES ###

    # Extract phenotype mentions
    ext_pheno_candidates {
      before: ${APP_HOME}/code/truncate_table.sh ${DBNAME} pheno_mentions
      style: tsv_extractor
      input: """SELECT doc_id,
              sent_id,
              wordidxs,
              words,
              poses,
              lemmas
            FROM 
              sentences_input"""
      output_relation: pheno_mentions
      udf: ${APP_HOME}/code/ext_pheno_candidates.py
      parallelism: ${PARALLELISM}
      dependencies: [new_sentence]
    }

    # For each supervised phenotype mention candidate, add an unsupervised copy
    ext_pheno_unsuperv_dupl: {
      style: sql_extractor
      sql: """INSERT INTO pheno_mentions
          SELECT
            id, 
            doc_id, 
            sent_id, 
            wordidxs, 
            mention_id || '_UNSUP',
            type || '_UNSUP',
            entity,
            words,
            NULL,
            features
          FROM
            pheno_mentions
          WHERE
            is_correct IS NOT NULL
          """
          #AND
          #	type <> 'PHENO_SUP_gene'
          #AND
          #	type <> 'PHENO_SUP_rand'
      dependencies: [ext_pheno_candidates, ext_genepheno_candidates]
    }

    # Add features for the phenotype candidates
    ext_pheno_features: {
      before: ${APP_HOME}/code/truncate_table.sh ${DBNAME} gene_features
      style: tsv_extractor
      input: """SELECT
              t0.doc_id,
              t0.sent_id,
              t0.wordidxs,
              t0.words,
              t0.poses,
              t0.ners,
              t0.lemmas,
              t0.dep_paths,
              t0.dep_parents,
              t1.mention_id,
              array_to_string(t1.wordidxs, '|^|')
           FROM
              sentences_input t0,
              pheno_mentions t1
          WHERE
              t0.doc_id = t1.doc_id and t0.sent_id = t1.sent_id
          """
      output_relation: pheno_features
      parallelism: ${PARALLELISM}
      dependencies: [ext_pheno_unsuperv_dupl]
    }


### GENE / PHENOTYPE ###

    # Extract gene <-> phenotype relation candidates
    ext_genepheno_candidates: {
      before: ${APP_HOME}/code/truncate_table.sh ${DBNAME} genepheno_relations
      style: tsv_extractor
      input: """ WITH g AS (
              SELECT 
                doc_id,
                sent_id,
                array_to_string(array_accum(genes.entity), '|^|') as entities,
                array_to_string(array_accum(array_to_string(genes.wordidxs, '|^|')), '!~!') as wordidxs, 
                array_to_string(array_accum(CASE WHEN genes.is_correct = true THEN 't' WHEN genes.is_correct = false THEN 'f' ELSE 'n' END), '|^|') as is_corrects,
                array_to_string(array_accum(genes.type), '|^|') as types
                FROM gene_mentions genes
                group by doc_id, sent_id
              ), h AS (
              SELECT
                doc_id,
                sent_id,
                array_to_string(array_accum(hpoterms.entity), '|^|') as entities, 
                array_to_string(array_accum(array_to_string(hpoterms.wordidxs, '|^|')), '!~!') as wordidxs,
                array_to_string(array_accum(CASE WHEN hpoterms.is_correct = true THEN 't' WHEN hpoterms.is_correct = false THEN 'f' ELSE 'n' END), '|^|') as is_corrects,
                array_to_string(array_accum(hpoterms.type), '|^|') as types
                FROM hpoterm_mentions hpoterms
                group by doc_id, sent_id
              )
            SELECT 
                sentences_input.doc_id,
                sentences_input.sent_id,
                max(sentences_input.wordidxs),
                max(sentences_input.words),
                max(sentences_input.poses),
                max(sentences_input.ners),
                max(sentences_input.lemmas),
                max(sentences_input.dep_paths),
                max(sentences_input.dep_parents),
                max(sentences_input.bounding_boxes),
                max(g.entities),
                max(g.wordidxs),
                max(g.is_corrects),
                max(g.types),
                max(h.entities),
                max(h.wordidxs),
                max(h.is_corrects),
                max(h.types)
            FROM
                g, h, sentences_input
            WHERE
                sentences_input.doc_id = h.doc_id
            AND		sentences_input.sent_id = h.sent_id
            AND		g.doc_id = sentences_input.doc_id
            AND		g.sent_id = sentences_input.sent_id
            GROUP BY sentences_input.doc_id, sentences_input.sent_id
          """
      output_relation: genepheno_relations
      udf: ${APP_HOME}/code/ext_genepheno_candidates.py
      dependencies: [ext_gene_superv_acronyms, ext_pheno_candidates]
      parallelism: ${PARALLELISM}
    }

    # For each supervised gene/phenotype relation candidate, add an unsupervised
    # copy
    ext_genepheno_unsuperv_dupl: {
      style: sql_extractor
      sql: """INSERT INTO genepheno_relations
          SELECT
            id,
            doc_id,
            sent_id_1,
            sent_id_2,
            relation_id || '_UNSUP',
            type || '_UNSUP',
            mention_id_1,
            mention_id_2,
            wordidxs_1,
            wordidxs_2,
            words_1,
            words_2,
            NULL,
            features
          FROM
            genepheno_relations
          WHERE
            is_correct IS NOT NULL
          """
      dependencies: [ext_genepheno_candidates]
    }

    # Add features for gene/phenotype relation candidates
    ext_genepheno_features: {
      style: tsv_extractor
      sql: """SELECT
              t0.doc_id,
              t0.sent_id,
              t0.wordidxs,
              t0.words,
              t0.poses,
              t0.ners,
              t0.lemmas,
              t0.dep_paths,
              t0.dep_parents,
              t1.relation_id,
              array_to_string(t1.wordidxs_1, '|^|'),
              array_to_string(t1.wordidxs_2, '|^|')
           FROM
              sentences_input t0,
              genepheno_relations t1
          WHERE
              t0.doc_id = t1.doc_id and t0.sent_id = t1.sent_id
        """
      output_relation: genepheno_features
      udf: ${APP_HOME}/code/ext_genepheno_candidates.py
      dependencies: [ext_genepheno_unsuperv_dupl]
    }

    # Use labeled data to supervise gp relation candidates
    label_gp_relations: {
      style: sql_extractor
      sql: """INSERT INTO genepheno_relations
          SELECT
            g.id,
            g.doc_id,
            g.sent_id_1,
            g.sent_id_2,
            g.relation_id || '_SUP',
            g.type,
            g.mention_id_1,
            g.mention_id_2,
            g.wordidxs_1,
            g.wordidxs_2,
            g.words_1,
            g.words_2,
            l.is_correct,
            g.features
          FROM
            genepheno_relations g,
            labeled_gp l
        where
          l.doc_id = g.doc_id
          and
          l.relation_id = g.relation_id
        """
      dependencies: [genepheno_relations, ext_genepheno_unsuperv_dupl]
    }

    # We need to make sure that each unsupervised G/P relation candidate has as
    # "originating" mention_ids two _unsupervised_ mentions. 
    ext_genepheno_fix_mentions: {
      style: sql_extractor
      sql: """UPDATE genepheno_relations
          SET
            mention_id_1 = (
              CASE WHEN mention_id_1 like 'GENE_SUP_%' 
                 THEN mention_id_1 || '_UNSUP'
                 ELSE mention_id_1
              END
            ),
            mention_id_2 = (
              CASE WHEN mention_id_2 like 'PHENO_SUP_%' 
                 THEN mention_id_2 || '_UNSUP'
                 ELSE mention_id_2
              END
            )
          WHERE is_correct is NULL;
        """
      dependencies: [ext_genepheno_unsuperv_dupl]
    }
  }


### PIPELINES ###

  # Pipeline: select which extractors / factors to run
  # pipeline.relearn_from: "/lfs/raiders4/0/senwu/deepdive/out/2015-01-11T104227/"
  pipeline.run: gg
  pipeline.pipelines {

    gg : [ classify_gene_mentions, classify_pheno_mentions, classify_genepheno_relations_features, gp_joint_1, gp_joint_2, abbre_gene_1, abbre_gene_2, abbre_hpoterm_1, abbre_hpoterm_2 ]
    
    dd : [ classify_gene_mentions, classify_hpoterm_mentions, classify_gene_hpoterm_relations_features ]
	  
    matteo: [ gene_hpoterm_relations, classify_gene_mentions, classify_hpoterm_mentions, classify_gene_hpoterm_relations_features, gp_joint_1, gp_joint_2 ]
	
    matteo2: [ find_acronyms, gene_supervision_acronyms, add_unsuper_dup_genes, add_geneRifs_mentions, add_unsuper_dup_hpoterms, gene_hpoterm_relations, label_gp_relations, add_unsuper_dup_genehpoterms, classify_gene_mentions, classify_hpoterm_mentions, classify_gene_hpoterm_relations_features, gp_joint_1, gp_joint_2 ]
	  
    matteo1: [ find_acronyms, extract_gene_mentions, gene_supervision_acronyms, add_unsuper_dup_genes, extract_geneRifs_mentions, add_geneRifs_mentions, extract_hpoterm_mentions, add_unsuper_dup_hpoterms, gene_hpoterm_relations, label_gp_relations, add_unsuper_dup_genehpoterms, classify_gene_mentions, classify_hpoterm_mentions, classify_gene_hpoterm_relations_features, gp_joint_1, gp_joint_2 ]
	  
    # Run only some extractors / factors
	  debug: []

	  # Genes
	  gene: [ext_gene_find_acronyms, ext_gene_candidates,
		  ext_gene_superv_acronyms, ext_gene_unsuperv_dupl, ext_gene_features,
		  ext_generifs_candidates, ext_generifs_features, add_generifs_mentions,
		  add_generifs_features, classify_gene_mentions]
	
    # Phenotypes
	  pheno: [ext_pheno_candidates, ext_pheno_unsuperv_dupl,
		  classify_pheno_mentions]
	
    # Gene/Phenotype
	  genepheno: [ext_genepheno_candidates, ext_genepheno_unsuperv_dupl,
		  ext_genepheno_fix_mentions, ext_genepheno_copy,
		  classify_genepheno_relations, classify_genepheno_relations_copies_gene,
		  classify_genepheno_relations_copies_pheno,
		  classify_genepheno_relations_copies_genepheno]
	
    # All extractors / factors
	  all: [ext_gene_find_acronyms, ext_gene_candidates, ext_gene_superv_acronyms,
	    ext_gene_unsuperv_dupl, ext_gene_features, ext_generifs_candidates,
	    ext_generifs_features, add_generifs_mentions, add_generifs_features,
	    ext_pheno_candidates, ext_pheno_unsuperv_dupl, ext_genepheno_candidates,
	    ext_genepheno_unsuperv_dupl, ext_genepheno_fix_mentions, ext_genepheno_copy,
	    classify_pheno_mentions classify_gene_mentions,
	    classify_genepheno_relations, classify_genepheno_relations_copies_gene,
	    classify_genepheno_relations_copies_pheno,
	    classify_genepheno_relations_copies_genepheno]
  }


### SCHEMA ###

  # Random variables
  schema.variables {
	  gene_mentions.is_correct: Boolean
	  pheno_mentions.is_correct: Boolean
	  genepheno_relations.is_correct: Boolean
	  #genepheno_relations_copies.is_correct: Boolean
  }


### INFERENCE RULES ###

  # Inference rules
  inference.factors {

    # Classify the gene mentions
    classify_gene_mentions {
      input_query: """
        SELECT 
          gm.id as "gene_mentions.id",
          gm.is_correct as "gene_mentions.is_correct",
          gf.feature as "feature"
        FROM 
          gene_mentions gm,
          gene_features gf
        WHERE 
          gm.mention_id = gf.mention_id
      """
      function: IsTrue(gene_mentions.is_correct)
      weight: "?(feature)"
    }

    # Conditional random field for gene mentions
    #factor_skip_chain_crf {
    #  input_query: """select *
    #	from (select gene_mentions_1.id as "gene_mentions.1.id",
    #	gene_mentions_2.id as "gene_mentions.2.id", gene_mentions_1.is_correct
    #	as "gene_mentions.1.is_correct", gene_mentions_2.is_correct as
    #	"gene_mentions.2.is_correct", row_number() over (partition by
    #	gene_mentions_1.id) as rn from gene_mentions gene_mentions_1,
    #	gene_mentions gene_mentions_2 where gene_mentions_1.doc_id = gene_mentions_2.doc_id and
    #	gene_mentions_1.words = gene_mentions_2.words and gene_mentions_1.id <
    #	gene_mentions_2.id) scrf where scrf.rn = 1""" 
    #  function: "Equal(gene_mentions.1.is_correct, gene_mentions.2.is_correct)"
    #  weight: "?"
    #}

    # Classify the phenotype mentions
    classify_phenotype_mentions {
      input_query: """
        SELECT
          pm.id as "pheno_mentions.id",
          pm.is_correct as "pheno_mentions.is_correct",
          pf.feature as "feature"
        FROM 
          pheno_mentions pm, 
          pheno_features pf
        WHERE
          pm.mention_id = pf.mention_id
      """
      function: IsTrue(pheno_mentions.is_correct)
      weight: "?(feature)"
    }

    # Classify the gene <-> phenotype relations
    classify_genepheno_relations {
      input_query: """
        SELECT
          gpr.id as "genepheno_relations.id",
          gpr.is_correct as "genepheno_relations.is_correct",
          gpf.feature as "feature"
        FROM 
          genepheno_relations gpr,
          genepheno_features gpf
        WHERE 
          gpr.relation_id = gpf.relation_id
      """
      function: IsTrue(genepheno_relations.is_correct)
      weight: "?(feature)"
    }

    # Add inference connection between G and GP
    gene_genepheno_joint {
      input_query: """
        SELECT
          gp.id as "genepheno_relations.id",
          gp.is_correct as "genepheno_relations.is_correct",
          gm.id as "gene_mentions.id",
          gm.is_correct as "gene_mentions.is_correct"
        FROM
          genepheno_relations gp,
          gene_mentions gm
        WHERE
          gp.doc_id = gm.doc_id AND
          gp.mention_id_1 = gm.mention_id
      """
      function: "Imply(genepheno_relations.is_correct, gene_mentions.is_correct)"
      weight: "?"
    }
    
    # Add inference connection between P and GP
    pheno_genepheno_joint {
      input_query: """
        SELECT
          gp.id as "genepheno_relations.id",
          gp.is_correct as "genepheno_relations.is_correct",
          pm.id as "pheno_mentions.id",
          pm.is_correct as "pheno_mentions.is_correct"
        FROM
          genepheno_relations gp,
          pheno_mentions pm
        WHERE
          gp.doc_id = pm.doc_id AND
          gp.mention_id_2 = pm.mention_id
      """
      function: "Imply(genepheno_relations.is_correct, pheno_mentions.is_correct)"
      weight: "?"
    }

    # Connections between candidates in same doc with same entity name
    abbre_gene_1 {
      input_query: """
        SELECT 
          array_accum(id) as "gene_mentions.id", 
          doc_id,
          entity
        FROM
          gene_mentions
        GROUP BY
          doc_id, 
          entity
      """
      function: "And(gene_mentions.is_correct)"
      weight: "?"
    }
    abbre_gene_2 {
      input_query: """
        SELECT 
          array_accum(id) as "gene_mentions.id",
          doc_id,
          entity 
        FROM
          gene_mentions
        GROUP BY
          doc_id, 
          entity
      """
      function: "And(!gene_mentions.is_correct)"
      weight: "?"
    }
    abbre_pheno_1 {
      input_query: """
        SELECT 
          array_accum(id) as "pheno_mentions.id",
          doc_id,
          entity 
        FROM
          pheno_mentions group by doc_id, entity
      """
      function: "And(pheno_mentions.is_correct)"
      weight: "?"
    }
    abbre_pheno_2 {
      input_query: """
        SELECT
          array_accum(id) as "pheno_mentions.id",
          doc_id,
          entity 
        FROM 
          pheno_mentions
        GROUP BY 
          doc_id,
          entity
      """
      function: "And(!pheno_mentions.is_correct)"
      weight: "?"
    }
  }

  sampler.sampler_args: "-l 300 -s 1 -i 500 --alpha 0.1 --diminish 0.99"
}

