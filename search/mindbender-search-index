#!/usr/bin/env bash
# mindbender-search-index -- Creates and maintains search index
#
# To update the search index with new searchable data produced by DeepDive, run:
# $ mindbender search-index update
# You can specify which searchable entities to update:
# $ mindbender search-index update [ENTITY]...
#
# For any reason, to destroy the search index, run:
# $ mindbender search-index destroy
##
# Author: Jaeho Shin <netj@cs.stanford.edu>
# Created: 2015-07-31
set -eu

# needs to work on a DeepDive app
DEEPDIVE_APP=$(find-deepdive-app)
cd "$DEEPDIVE_APP"

# use the DeepDive app's folder name for the ES index name
: ${ELASTICSEARCH_INDEX_NAME:=$(basename "$PWD")}

# parse command-line args
case ${1:-} in
    update|status|destroy)
        # make sure elasticsearch is running
        ${ELASTICSEARCH_RUNNING:-false} ||
            exec keep-elasticsearch-during -- "$0" "$@"
        Action=$1; shift
        ;;
    *)
        usage "$0" "No action given: update, status, or destroy"
esac

# simple wrapper for elasticsearch HTTP API
esAPI() {
    local verb=$1 path=$2; shift 2
    curl -X$verb "$ELASTICSEARCH_BASEURL$path" "$@"
    echo  # because ES does not put an EOL
}
# shorthand for APIs on the index
esAPIx() {
    local verb=$1 path=$2; shift 2
    esAPI "$verb" "/$ELASTICSEARCH_INDEX_NAME$path" "$@"
}

# perform action on search index
case $Action in
    update)
        schemaJSON=$(mktemp ${TMPDIR:-/tmp}/mindbender-search-index-schema.XXXXXXX)
        trap "rm -f $schemaJSON" EXIT
        jqSchema() { jqDDlog <"$schemaJSON" "$@"; }

        # TODO keep this schema exporting under deepdive command?
        ddlog export-schema app.ddlog >"$schemaJSON"

        [[ $# -gt 0 ]] ||
            # default to all searchable entities discovered from DDlog
            eval set -- $(jqSchema 'relations | hasColumnsAnnotated(.name == "key") | .name | @sh')
        ## create ES indexes corresponding to each entity
        #for entity; do esAPIx PUT "/$entity/"; done

        # parent-child mapping (See: https://www.elastic.co/guide/en/elasticsearch/guide/current/parent-child-mapping.html)
        jqSchema '
            [ relations | {
                    key: .name,
                    value: relationsReferenced | map(.relation)[0] |
                        (if . then { _parent: { type: . } } else {} end)
            } ] |
            { mappings: from_entries }
        ' | esAPIx PUT "/"

        eval "$(
        jqSchema 'relations | select(keyColumns | length > 0) | {
                relation: .,
                columnsForKey: keyColumns | map(.name),
                columnsForParent: relationsReferenced | map(.byColumn | map(.name))[0]
            } |
            # output shell commands that load data
            "
                echo \("Updating \(.relation.name)..." | @sh)
                # unload data from database in json lines
                deepdive sql eval \(.relation | sqlForRelation | @sh) format=json |
                # TODO split records into parallelizable size
                # use a jq program that produces elasticsearch bulk load action for each JSON record
                jq -c \(
                    # index action/metadat
                    "{index:{
                        _id: \(
                            if .columnsForKey | length == 1 then
                                # use primary key (single column)
                                ".\(.columnsForKey[0])"
                            else
                                # or join with underscore if key is multiple columns
                                "\"\(.columnsForKey | map("\\(.\(.))") | join("_"))\""
                            end
                        )
                        # TODO _parent from .columnsForParent
                    }},
                    . # followed by the actual document to index
                    " | @sh) |
                # send them to elasticsearch
                esAPIx PUT '\''/\(.relation.name)/_bulk'\'' --data-binary @-
            "'
        )"
        ;;

    status)
        esAPI GET '/_stats'
        ;;

    destroy)
        # delete the ES index
        esAPIx DELETE "/"
        ;;

    *)
        error "$Action: unknown action"
esac
